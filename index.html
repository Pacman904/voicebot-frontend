<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Voice Assistant with Google Gemini</title>
  <style>
    body { font-family: Arial; margin: 0; padding: 20px; background: #f0f2f5; }
    .container { max-width: 600px; margin: auto; background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    #micButton { background: #10B981; width: 80px; height: 80px; border-radius: 50%; border: none; cursor: pointer; margin: 20px auto; display: block; color: white; font-size: 24px; }
    #micButton.stop { background: #EF4444; }
    #status { color: #059669; text-align: center; display: none; }
    #logs { background: #1f2937; color: white; padding: 15px; border-radius: 8px; font-family: monospace; height: 200px; overflow-y: auto; }
  </style>
</head>
<body>
  <div class="container">
    <div id="status">‚óè LIVE</div>
    <div id="logs"></div>
    <button id="micButton" onclick="toggleConnection()">üé§</button>
    <audio id="audioOutput" controls autoplay style="width: 100%; margin-top: 20px;"></audio>
  </div>
  <script src="https://unpkg.com/openai/dist/openai.min.js"></script>
  <script>
    const openai = new OpenAI({
      apiKey: "AIzaSyASxQq1OC-7UOpunlp5hrjckKPq9gPUA5I", // Ersetzen Sie dies durch Ihren Google Gemini API-Schl√ºssel
      baseURL: "https://generativelanguage.googleapis.com/v1beta/openai/"
    });

    let peerConnection = null;
    let mediaStream = null;
    let dc = null;

    function log(message) {
      const logs = document.getElementById('logs');
      logs.textContent += `[${new Date().toLocaleTimeString()}] ${message}\n`;
      logs.scrollTop = logs.scrollHeight;
    }

    async function initConnection() {
      try {
        log("Verbindung wird initialisiert...");
        const session = await openai.realtime.sessions.create({
          model: "gemini-2.0-flash",
          voice: "verse",
          modalities: ["audio", "text"],
          output_audio_format: "pcm16",
          input_audio_format: "pcm16",
          instructions: "Du bist ein hilfreicher, witziger und freundlicher KI-Assistent. Dein Wissen reicht bis Oktober 2023. Verhalte dich wie ein Mensch, aber denke daran, dass du keiner bist. Deine Stimme und Pers√∂nlichkeit sollten warm, lebhaft und verspielt sein. Sprich schnell und verwende, falls m√∂glich, Funktionen.",
          turn_detection: {
            type: "server_vad",
            threshold: 0.5,
            prefix_padding_ms: 300,
            silence_duration_ms: 200,
            create_response: true,
            interrupt_response: true
          }
        });

        peerConnection = new RTCPeerConnection({
          iceServers: session.iceServers,
          iceTransportPolicy: "relay"
        });

        peerConnection.oniceconnectionstatechange = () => {
          log(`ICE Connection State: ${peerConnection.iceConnectionState}`);
        };

        mediaStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: 24000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true
          }
        });

        mediaStream.getTracks().forEach(track => {
          peerConnection.addTrack(track, mediaStream);
          log(`Audio-Track hinzugef√ºgt: ${track.id}`);
        });

        peerConnection.ontrack = async (event) => {
          log("Eingehender Medienstream erkannt");
          const audioElement = document.getElementById('audioOutput');
          audioElement.srcObject = event.streams[0];
          audioElement.oncanplaythrough = () => {
            audioElement.play().catch(err => {
              log(`Wiedergabefehler: ${err.message}`);
            });
          };
        };

        dc = peerConnection.createDataChannel("oai-events");
        dc.onopen = () => {
          log("Datenkanal ge√∂ffnet");
        };

        dc.onmessage = (event) => {
          const message = JSON.parse(event.data);
          log(`Nachricht empfangen: ${JSON.stringify(message)}`);
          
          if (message.type === "response.audio.delta") {
            log("Audio-Delta empfangen");
          } else if (message.type === "response.text.delta") {
            log(`Textantwort: ${message.delta}`);
          } else if (message.type === "response.done" && message.response.status === "failed") {
            log(`Fehler bei der Antwort: ${JSON.stringify(message.response.status_details)}`);
          }
        };

        const offer = await peerConnection.createOffer();
        await peerConnection.setLocalDescription(offer);
        
        const answer = await openai.realtime.forwardToOpenAI({
          clientSecret: session.clientSecret,
          sdp: offer.sdp
        });
        
        await peerConnection.setRemoteDescription(
          new RTCSessionDescription({
            type: 'answer',
            sdp: answer.sdp
          })
        );

        document.getElementById('status').style.display = 'block';
        document.getElementById('micButton').classList.add('stop');
        document.getElementById('micButton').textContent = '‚èπÔ∏è';
        log("Verbindung erfolgreich!");
      } catch (error) {
        log(`Fehler: ${error.message || JSON.stringify(error)}`);
      }
    }

    async function toggleConnection() {
      const micButton = document.getElementById('micButton');
      if (peerConnection?.connectionState === 'connected') {
        peerConnection.close();
        mediaStream?.getTracks().forEach(track => track.stop());
        document.getElementById('status').style.display = 'none';
        document.getElementById('audioOutput').srcObject = null;
        micButton.classList.remove('stop');
        micButton.textContent = 'üé§';
        log("Verbindung getrennt");
      } else {
        await initConnection();
      }
    }
  </script>
</body>
</html>
