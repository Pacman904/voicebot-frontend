<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenAI Voice Assistant</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background-color: #f4f4f4;
            margin: 0;
        }
        .container {
            display: flex;
            align-items: center;
            gap: 20px;
        }
        .phone {
            width: 300px;
            height: 600px;
            background-color: #111;
            border-radius: 30px;
            padding: 20px;
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.3);
            position: relative;
            overflow: hidden;
        }
        .phone-screen {
            background-color: white;
            height: 100%;
            border-radius: 20px;
            overflow: hidden;
            display: flex;
            flex-direction: column;
        }
        .phone-status {
            height: 30px;
            background-color: #f8f8f8;
            border-bottom: 1px solid #ddd;
            display: flex;
            align-items: center;
            padding: 0 15px;
        }
        .call-status {
            font-size: 14px;
            font-weight: bold;
            color: #4CAF50;
            display: none;
        }
        .phone-content {
            flex: 1;
            padding: 15px;
            overflow-y: auto;
            background-color: #f9f9f9;
        }
        .message-box {
            background-color: white;
            border-radius: 10px;
            padding: 10px;
            margin-bottom: 10px;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
            word-wrap: break-word;
        }
        .phone-bottom {
            height: 80px;
            background-color: #f8f8f8;
            display: flex;
            justify-content: center;
            align-items: center;
            border-top: 1px solid #ddd;
        }
        .call-button {
            width: 60px;
            height: 60px;
            border-radius: 50%;
            background-color: #4CAF50;
            display: flex;
            justify-content: center;
            align-items: center;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        .call-button.active {
            background-color: #f44336;
        }
        .call-button i {
            color: white;
            font-size: 24px;
        }
        .speech-bubble {
            position: relative;
            background: #ffffff;
            border-radius: 15px;
            padding: 20px;
            width: 250px;
            min-height: 100px;
            max-height: 400px;
            overflow-y: auto;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            display: none;
        }
        .speech-bubble:after {
            content: '';
            position: absolute;
            left: 0;
            top: 30px;
            width: 0;
            height: 0;
            border: 15px solid transparent;
            border-right-color: #ffffff;
            border-left: 0;
            margin-top: -15px;
            margin-left: -15px;
        }
        .error {
            color: #f44336;
            font-weight: bold;
        }
        audio {
            display: none;
        }
    </style>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css">
</head>
<body>
    <div class="container">
        <div class="phone">
            <div class="phone-screen">
                <div class="phone-status">
                    <div id="callStatus" class="call-status">Active Call</div>
                </div>
                <div id="phoneContent" class="phone-content">
                    <div class="message-box">
                        Ready to connect to OpenAI voice assistant. Press the green button to start.
                    </div>
                </div>
                <div class="phone-bottom">
                    <div id="callButton" class="call-button">
                        <i class="fas fa-phone"></i>
                    </div>
                </div>
            </div>
        </div>
        <div id="speechBubble" class="speech-bubble">
            <p>OpenAI responses will appear here once connected.</p>
        </div>
    </div>
     <script src="https://unpkg.com/parse/dist/parse.min.js"></script>
    <script>
        // Initialize Parse
        Parse.initialize("uNEbQKjymSX8qmK9gorQNRbSuaV23eMHriF2Yeoi", "NY08Fa7grB4I1AOOcrjKN2b9w6sWke5GCA8rpxBM");
        Parse.serverURL = "https://parseapi.back4app.com";

        // State management
        const state = {
            peerConnection: null,
            dataChannel: null,
            isCallActive: false,
            sessionId: null,
            audioContext: null,
            mediaStream: null,
            audioElement: null,
            audioStreamTrack: null,
            clientSecret: null,
            openAIModel: "gpt-4o-realtime-preview-2024-12-17"
        };

        // DOM elements
        const elements = {
            callButton: document.getElementById('callButton'),
            phoneContent: document.getElementById('phoneContent'),
            callStatus: document.getElementById('callStatus'),
            speechBubble: document.getElementById('speechBubble')
        };

        // Utility functions
        function addMessage(message, isError = false) {
            const messageBox = document.createElement('div');
            messageBox.className = 'message-box';
            if (isError) messageBox.classList.add('error');
            messageBox.textContent = message;
            elements.phoneContent.appendChild(messageBox);
            elements.phoneContent.scrollTop = elements.phoneContent.scrollHeight;
        }

        function updateSpeechBubble(text) {
            elements.speechBubble.innerHTML = `<p>${text}</p>`;
            elements.speechBubble.style.display = 'block';
        }

        function initializeWebRTC(iceServers) {
            try {
                const configuration = { iceServers };
                state.peerConnection = new RTCPeerConnection(configuration);
                
                // ICE Candidate handling
                state.peerConnection.onicecandidate = (event) => {
                    if (event.candidate) {
                        console.log("ICE Candidate:", event.candidate);
                    }
                };

                // Connection state handling
                state.peerConnection.onconnectionstatechange = () => {
                    console.log("Connection state:", state.peerConnection.connectionState);
                    switch(state.peerConnection.connectionState) {
                        case "connected":
                            elements.callStatus.style.display = "block";
                            addMessage("Connection established!");
                            break;
                        case "disconnected":
                        case "failed":
                            endCall();
                            addMessage("Connection lost", true);
                            break;
                    }
                };

                // Audio track handling
                state.peerConnection.ontrack = (event) => {
                    if (!state.audioElement) {
                        state.audioElement = document.createElement("audio");
                        state.audioElement.autoplay = true;
                        document.body.appendChild(state.audioElement);
                    }
                    state.audioElement.srcObject = event.streams[0];
                };

                // Data channel setup
                state.dataChannel = state.peerConnection.createDataChannel("oai-events");
                state.dataChannel.onopen = () => {
                    addMessage("Data channel ready");
                    console.log("Data channel opened");
                };
                
                state.dataChannel.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        console.log("OpenAI Event:", data);
                        
                        if (data.type === "transcript") {
                            updateSpeechBubble(data.text);
                        } else if (data.type === "error") {
                            handleOpenAIError(data);
                        }
                    } catch (error) {
                        console.error("Error parsing message:", error);
                    }
                };

                return state.peerConnection;
            } catch (error) {
                console.error("WebRTC Error:", error);
                throw error;
            }
        }

        function handleOpenAIError(errorData) {
            const errorMessage = errorData.error?.message || 
                              errorData.message || 
                              "Unknown OpenAI error";
            addMessage(`Error: ${errorMessage}`, true);
            endCall();
        }

        async function startUserMedia() {
            try {
                state.mediaStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: true, 
                    video: false 
                });
                
                state.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                // Add audio track to peer connection
                state.mediaStream.getTracks().forEach(track => {
                    if (track.kind === 'audio') {
                        state.audioStreamTrack = track;
                        state.peerConnection.addTrack(track, state.mediaStream);
                    }
                });
                
                addMessage("Microphone ready");
                return true;
            } catch (error) {
                console.error("Media Error:", error);
                addMessage(`Media Error: ${error.message}`, true);
                throw error;
            }
        }

        async function establishOpenAIConnection() {
            try {
                // Create and set local description
                const offer = await state.peerConnection.createOffer({
                    offerToReceiveAudio: true,
                    offerToReceiveVideo: false
                });
                await state.peerConnection.setLocalDescription(offer);

                // Connect to OpenAI with the ephemeral key
                const response = await fetch("https://api.openai.com/v1/realtime/sessions", {
                    method: "POST",
                    headers: {
                        "Authorization": `Bearer ${state.clientSecret}`,
                        "Content-Type": "application/json"
                    },
                    body: JSON.stringify({
                        sdp: offer.sdp,
                        model: state.openAIModel
                    })
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.error?.message || "OpenAI connection failed");
                }

                const answerData = await response.json();
                await state.peerConnection.setRemoteDescription({
                    type: "answer",
                    sdp: answerData.sdp
                });

                addMessage("Connected to OpenAI");
                return true;
            } catch (error) {
                console.error("OpenAI Connection Error:", error);
                throw error;
            }
        }

        async function startConnection() {
            try {
                addMessage("Initializing connection...");
                
                // Get session data from backend
                const sessionData = await Parse.Cloud.run("createEphemeralSession", {
                    model: state.openAIModel,
                    voice: "alloy"
                });

                if (!sessionData?.clientSecret) {
                    throw new Error("Invalid session data from server");
                }

                state.sessionId = sessionData.sessionId;
                state.clientSecret = sessionData.clientSecret;

                // Initialize WebRTC
                initializeWebRTC(sessionData.iceServers);
                await startUserMedia();
                await establishOpenAIConnection();

                return true;
            } catch (error) {
                console.error("Connection Error:", error);
                addMessage(`Connection failed: ${error.message}`, true);
                endCall();
                return false;
            }
        }

        function endCall() {
            // Clean up media streams
            if (state.mediaStream) {
                state.mediaStream.getTracks().forEach(track => track.stop());
                state.mediaStream = null;
            }
            
            if (state.audioStreamTrack) {
                state.audioStreamTrack.stop();
                state.audioStreamTrack = null;
            }
            
            // Clean up WebRTC connection
            if (state.peerConnection) {
                state.peerConnection.close();
                state.peerConnection = null;
            }
            
            // Clean up audio element
            if (state.audioElement) {
                state.audioElement.pause();
                state.audioElement.srcObject = null;
                state.audioElement.remove();
                state.audioElement = null;
            }
            
            // Reset UI
            elements.callButton.classList.remove('active');
            elements.callStatus.style.display = "none";
            elements.speechBubble.style.display = 'none';
            state.isCallActive = false;
            
            addMessage("Call ended");
        }

        async function toggleCall() {
            if (state.isCallActive) {
                endCall();
            } else {
                elements.callButton.classList.add('active');
                state.isCallActive = await startConnection();
                if (!state.isCallActive) {
                    elements.callButton.classList.remove('active');
                }
            }
        }

        // Event listeners
        elements.callButton.addEventListener('click', toggleCall);

        window.addEventListener('beforeunload', endCall);
        
        // Audio context resume handler
        document.addEventListener('click', () => {
            if (state.audioContext && state.audioContext.state === 'suspended') {
                state.audioContext.resume().then(() => {
                    console.log("Audio context resumed");
                });
            }
        }, { once: true });
    </script>
</body>
</html>
