<!DOCTYPE html>
<html>
<head>
  <script src="https://npmcdn.com/parse/dist/parse.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/webrtc-adapter/8.2.3/adapter.min.js"></script>

  <style>
    #voiceBotUI {
      width: 300px;
      height: 400px;
      border: 2px solid #000;
      position: relative;
      font-family: Arial, sans-serif;
    }

    #statusBar {
      height: 30px;
      background: #000;
      color: #ff0000;
      padding: 5px;
      display: none;
    }

    #logContent {
      height: calc(100% - 70px);
      overflow-y: auto;
      padding: 10px;
      background: #f0f0f0;
    }

    #callButton {
      position: absolute;
      bottom: 10px;
      left: 50%;
      transform: translateX(-50%);
      padding: 10px 20px;
      background: #4CAF50;
      color: white;
      border: none;
      cursor: pointer;
    }

    .activeCall {
      background: #ff4444 !important;
    }

    .error {
      color: red;
      font-size: 0.9em;
      margin: 5px 0;
    }

    .bot {
      color: #2c3e50;
      background: #ecf0f1;
      padding: 5px;
      margin: 5px 0;
      border-radius: 3px;
    }

    .user {
      color: #2980b9;
      background: #e8f6fe;
      padding: 5px;
      margin: 5px 0;
      border-radius: 3px;
    }
  </style>
</head>
<body>
  <div id="voiceBotUI">
    <div id="statusBar"></div>
    <div id="logContent"></div>
    <button id="callButton">Start Call</button>
  </div>

  <script>
    // Parse-Initialisierung
    Parse.initialize(
      "uNEbQKjymSX8qmK9gorQNRbSuaV23eMHriF2Yeoi",
      "NY08Fa7grB4I1AOOcrjKN2b9w6sWke5GCA8rpxBM"
    );
    Parse.serverURL = "https://parseapi.back4app.com/";

    // Globale Variablen
    let isCallActive = false;
    let peerConnection;
    let dataChannel;
    let mediaStream;
    const voiceRecognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    
    // UI-Elemente
    const callButton = document.getElementById('callButton');
    const statusBar = document.getElementById('statusBar');
    const logContent = document.getElementById('logContent');

    // Sprachkonfiguration
    voiceRecognition.continuous = true;
    voiceRecognition.interimResults = true;
    voiceRecognition.lang = 'auto';

    // Event-Handler fÃ¼r Call-Button
    callButton.addEventListener('click', async () => {
      isCallActive = !isCallActive;
      
      if (isCallActive) {
        try {
          activateUI();
          await initVoiceBot();
          startVoiceRecognition();
        } catch (error) {
          handleError(error);
          toggleOff();
        }
      } else {
        toggleOff();
      }
    });

    // UI aktivieren
    function activateUI() {
      statusBar.style.display = 'block';
      statusBar.textContent = 'ON AIR';
      callButton.textContent = 'Stop Call';
      callButton.classList.add('activeCall');
    }

    // WebRTC-Initialisierung
    async function initVoiceBot() {
      try {
        // 1. Session und ICE-Server holen
        const [sessionData, iceServers] = await Promise.all([
          Parse.Cloud.run('createRealtimeSession'),
          Parse.Cloud.run('getIceServers')
        ]);

        // 2. PeerConnection erstellen
        peerConnection = new RTCPeerConnection({ iceServers });

        // 3. Audio-Handling
        const audioElement = new Audio();
        peerConnection.ontrack = (event) => {
          audioElement.srcObject = event.streams[0];
          audioElement.play();
        };

        // 4. Mikrofon-Stream
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        peerConnection.addTrack(mediaStream.getTracks()[0]);

        // 5. Data Channel
        dataChannel = peerConnection.createDataChannel("oai-events");
        setupDataChannel();

        // 6. SDP-Handshake
        const offer = await peerConnection.createOffer();
        await peerConnection.setLocalDescription(offer);

        // ðŸ”´ WICHTIG: SDP als roher Text senden
        const sdpResponse = await fetch(
          `https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17`,
          {
            method: "POST",
            body: offer.sdp, // Roher SDP-Text
            headers: {
              Authorization: `Bearer ${sessionData.client_secret}`, 
  	"Content-Type": "application/sdp"
            }
          }
        );

        const answerSDP = await sdpResponse.text();
        await peerConnection.setRemoteDescription(
          new RTCSessionDescription({
            type: 'answer',
            sdp: answerSDP
          })
        );

      } catch (error) {
        throw new Error(`Verbindungsfehler: ${error.message}`);
      }
    }

    // Data-Channel konfigurieren
    function setupDataChannel() {
      dataChannel.onmessage = (event) => {
        try {
          const response = JSON.parse(event.data);
          if (response.type === 'response.update') {
            handleBotResponse(response.response.content);
          }
        } catch (error) {
          console.error('Datenverarbeitungsfehler:', error);
        }
      };
    }

    // Bot-Antwort verarbeiten
    function handleBotResponse(text) {
      // Sprachausgabe
      const speech = new SpeechSynthesisUtterance(text);
      speech.lang = 'auto';
      speech.rate = 1.1;
      window.speechSynthesis.speak(speech);

      // Log-Eintrag
      const messageDiv = document.createElement('div');
      messageDiv.className = 'bot';
      messageDiv.textContent = `${new Date().toLocaleTimeString()}: ${text}`;
      logContent.prepend(messageDiv);
    }

    // Spracherkennung starten
    function startVoiceRecognition() {
      voiceRecognition.start();
      
      voiceRecognition.onresult = (event) => {
        const transcript = Array.from(event.results)
          .map(result => result[0].transcript)
          .join('');

        if (event.results[0].isFinal && dataChannel?.readyState === 'open') {
          sendUserInput(transcript);
        }
      };
    }

    // Nutzereingabe senden
    function sendUserInput(text) {
      const message = {
        type: "response.create",
        response: {
          modalities: ["text"],
          instructions: `
            [Benutzeranfrage: ${text}]
            Antwortregeln:
            1. HÃ¶flich und prÃ¤zise (3-4 SÃ¤tze)
            2. Quelle: www.palettix.com
            3. Sprache anpassen
            4. Keine technischen Details
          `
        }
      };
      
      try {
        dataChannel.send(JSON.stringify(message));
        
        // Nutzernachricht loggen
        const userDiv = document.createElement('div');
        userDiv.className = 'user';
        userDiv.textContent = `${new Date().toLocaleTimeString()}: ${text}`;
        logContent.prepend(userDiv);
      } catch (error) {
        console.error('Sendefehler:', error);
      }
    }

    // Cleanup
    function toggleOff() {
      isCallActive = false;
      statusBar.style.display = 'none';
      callButton.textContent = 'Start Call';
      callButton.classList.remove('activeCall');
      
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
      }
      if (peerConnection) {
        peerConnection.close();
      }
      if (voiceRecognition) {
        voiceRecognition.stop();
      }
      window.speechSynthesis.cancel();
    }

    // Fehlerbehandlung
    function handleError(error) {
      const errorDiv = document.createElement('div');
      errorDiv.className = 'error';
      errorDiv.textContent = `${new Date().toLocaleTimeString()}: ${error.message}`;
      logContent.prepend(errorDiv);
      console.error(error);
    }

    // Globale Fehler abfangen
    window.addEventListener('error', (event) => {
      handleError(event.error);
    });
  </script>
</body>
</html>leError(event.error);
    });
  </script>
</body>
</html>
