<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>OpenAI VoiceBot</title>
  <style>
    body { 
      font-family: Arial; 
      display: flex; 
      justify-content: center; 
      align-items: center; 
      height: 100vh; 
      background: #f4f4f4; 
      margin: 0;
    }
    .container { 
      background: white; 
      padding: 30px; 
      border-radius: 15px; 
      box-shadow: 0 4px 30px rgba(0,0,0,0.15); 
      width: 90%; 
      max-width: 600px; 
      height: 80%; 
      display: flex; 
      flex-direction: column; 
    }
    .mic-btn {
      background: #28a745;
      border: none;
      border-radius: 50%;
      width: 100px;
      height: 100px;
      cursor: pointer;
      font-size: 24px;
      color: white;
      outline: none;
      transition: background 0.3s;
      margin: auto;
      margin-bottom: 20px;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    .mic-btn.disconnected {
      background: #28a745;
    }
    .mic-btn.connected {
      background: #dc3545;
    }
    #statusLabel {
      text-align: center;
      margin-bottom: 30px;
      font-size: 24px;
      color: green;
      display: none;
    }
    #consoleLogs {
      flex: 1;
      padding: 15px;
      background: #212529;
      color: #cccccc;
      font-family: monospace;
      overflow-y: auto;
      white-space: pre-line;
      margin-bottom: 10px;
    }
  </style>
</head>
<body>
  <div class="container">
    <div id="statusLabel">on Air</div>
    <div id="consoleLogs"></div>
    <button id="micButton" class="mic-btn disconnected" onclick="toggleConnection()">
      <i class="fas fa-microphone"></i>
    </button>
  </div>

  <!-- Font Awesome Script mit deinem Kit -->
  <script src="https://kit.fontawesome.com/845924f09c.js" crossorigin="anonymous"></script>
  
  <script src="https://unpkg.com/parse/dist/parse.min.js"></script>
  <script>
    Parse.initialize("uNEbQKjymSX8qmK9gorQNRbSuaV23eMHriF2Yeoi", "NY08Fa7grB4I1AOOcrjKN2b9w6sWke5GCA8rpxBM");
    Parse.serverURL = "https://parseapi.back4app.com/";

    let peerConnection = null;
    let userStream = null;
    let dc = null;
    let isSpeaking = false;
    let logsDiv = document.getElementById('consoleLogs');

    function updateUIConnectionState(state) {
      const micBtn = document.getElementById('micButton');
      const statusLabel = document.getElementById('statusLabel');
      if (state === 'connected') {
        micBtn.classList.remove('disconnected');
        micBtn.classList.add('connected');
        statusLabel.style.display = 'block';
      } else {
        micBtn.classList.remove('connected');
        micBtn.classList.add('disconnected');
        statusLabel.style.display = 'none';
      }
    }

    function logMessage(message) {
      logsDiv.textContent += `[${new Date().toISOString()}] ${message}\n`;
      logsDiv.scrollTop = logsDiv.scrollHeight;
    }

    async function initializeWebRTC(iceServers, clientSecret, parseSessionId) {
      const configuration = {
        iceServers: iceServers || [
          { urls: "stun:stun.l.google.com:19302" },
          { urls: "turn:numb.viagenie.ca", username: "webrtc@live.com", credential: "muazkh" }
        ]
      };

      peerConnection = new RTCPeerConnection(configuration);
      peerConnection.onicecandidate = async (event) => {
        if (event.candidate) {
          try {
            await sendSignalingData(parseSessionId, {
              type: "candidate",
              candidate: event.candidate.candidate,
              sdpMid: event.candidate.sdpMid,
              sdpMLineIndex: event.candidate.sdpMLineIndex
            });
            logMessage("ICE-Kandidat gesendet");
          } catch (error) {
            logMessage("Fehler beim Senden des ICE-Kandidaten");
          }
        }
      };

      peerConnection.ontrack = (event) => {
        const audioEl = document.createElement('audio');
        audioEl.srcObject = event.streams[0];
        audioEl.controls = true;
        audioEl.style.width = '100%';
        audioEl.autoplay = true;
        document.body.appendChild(audioEl);
      };

      dc = peerConnection.createDataChannel("oaiControlEvents");
      dc.onmessage = (e) => {
        const event = JSON.parse(e.data);
        logMessage(`OpenAI Event: ${JSON.stringify(event)}`);
        if (event.type === "error") {
          logMessage("OpenAI-Fehler: " + event.error.message, "error");
        }
      };

      return peerConnection;
    }

    async function startConnection() {
      try {
        const response = await Parse.Cloud.run("createEphemeralSession", {
          model: "gpt-4o-mini-realtime-preview-2024-12-17",
          voice: "verse"
        });

        userStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        userStream.getAudioTracks().forEach(track => {
          track.applyConstraints({ echoCancellation: true });
          peerConnection.addTrack(track);
        });

        peerConnection = await initializeWebRTC(
          response.iceServers, 
          response.clientSecret, 
          response.sessionId
        );

        const offer = await peerConnection.createOffer({ offerToReceiveAudio: true });
        await peerConnection.setLocalDescription(offer);
        logMessage("SDP-Angebot gesendet");

        await Parse.Cloud.run("sendSignalingData", {
          sessionId: response.sessionId,
          data: { type: "offer", sdp: offer.sdp }
        });

        const sdpResponse = await fetch(`https://api.openai.com/v1/realtime?model=gpt-4o-mini-realtime-preview-2024-12-17`, {
          method: "POST",
          body: offer.sdp,
          headers: {
            Authorization: `Bearer ${response.clientSecret}`,
            "Content-Type": "application/sdp"
          }
        });

        if (!sdpResponse.ok) {
          throw new Error("Fehler bei OpenAI-SDP-Verarbeitung");
        }

        const answerSdp = await sdpResponse.text();
        await peerConnection.setRemoteDescription({ type: "answer", sdp: answerSdp });
        logMessage("SDP-Antwort empfangen");

        const signalingData = await Parse.Cloud.run("getSignalingData", { sessionId: response.sessionId });
        signalingData.forEach(data => {
          if (data.type === "candidate") {
            const candidate = new RTCIceCandidate({
              candidate: data.candidate,
              sdpMid: data.sdpMid,
              sdpMLineIndex: data.sdpMLineIndex
            });
            peerConnection.addIceCandidate(candidate);
          }
        });

        updateUIConnectionState(peerConnection.connectionState);
      } catch (error) {
        logMessage(`Verbindungsfehler: ${error.message}`, "error");
      }
    }

    peerConnection?.addEventListener('connectionstatechange', () => {
      updateUIConnectionState(peerConnection?.connectionState);
      logMessage(`Verbindungsstatus: ${peerConnection?.connectionState}`);
    });

    function startAudioProcessing() {
      const audioContext = new AudioContext();
      const processor = audioContext.createScriptProcessor(4096, 1, 1);
      userStream.getAudioTracks().forEach(track => {
        const source = audioContext.createMediaStreamTrackSource(track);
        source.connect(processor);
      });
      processor.connect(audioContext.destination);

      processor.onaudioprocess = (event) => {
        const buffer = event.inputBuffer.getChannelData(0);
        const volume = Math.sqrt(buffer.reduce((sum, sample) => sum + sample ** 2, 0) / buffer.length);
        
        if (volume > 0.1) {
          isSpeaking = true;
          dc.send(JSON.stringify({ type: "input_audio_buffer.append", audio: Array.from(buffer) }));
          logMessage("Audio-Input buffer append");
        } else {
          if (isSpeaking) {
            setTimeout(() => {
              if (!isSpeaking) {
                dc.send(JSON.stringify({ type: "input_audio_buffer.commit" }));
                logMessage("Audio-Input buffer commit");
              }
            }, 1000);
          }
        }
      };
    }

    async function toggleConnection() {
      if (peerConnection?.connectionState === 'connected') {
        await stopConnection();
      } else {
        await startConnection();
      }
    }

    async function stopConnection() {
      if (peerConnection) {
        peerConnection.close();
        peerConnection = null;
      }
      if (userStream) {
        userStream.getTracks().forEach(track => track.stop());
        userStream = null;
      }
      logMessage("Verbindung beendet");
    }

    async function sendSignalingData(sessionId, data) {
      try {
        await Parse.Cloud.run("sendSignalingData", {
          sessionId: sessionId,
          data: data
        });
      } catch (error) {
        logMessage("Signaling-Fehler: " + error.message, "error");
      }
    }

    window.addEventListener('beforeunload', stopConnection);
  </script>
</body>
</html>
