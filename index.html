<!-- Index.html -->
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Voice Assistant</title>
  <style>
    body { 
      font-family: Arial;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
      background: #f0f2f5;
    }
    .container {
      background: white;
      padding: 2rem;
      border-radius: 1rem;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
      width: 90%;
      max-width: 600px;
    }
    #micButton {
      background: #10B981;
      width: 80px;
      height: 80px;
      border-radius: 50%;
      border: none;
      cursor: pointer;
      color: white;
      display: block;
      margin: 1rem auto;
    }
    #status {
      color: #059669;
      text-align: center;
      margin: 1rem 0;
      display: none;
    }
    #logs {
      background: #1F2937;
      color: white;
      padding: 1rem;
      border-radius: 0.5rem;
      font-family: monospace;
      height: 200px;
      overflow-y: auto;
    }
  </style>
</head>
<body>
  <div class="container">
    <div id="status">‚óè LIVE</div>
    <div id="logs"></div>
    <button id="micButton" onclick="toggle()">
      <i class="fas fa-microphone"></i>
    </button>
    <audio id="audioOutput" controls style="width: 100%"></audio>
  </div>

  <script src="https://kit.fontawesome.com/845924f09c.js"></script>
  <script src="https://unpkg.com/parse/dist/parse.min.js"></script>
  <script>
    Parse.initialize("uNEbQKjymSX8qmK9gorQNRbSuaV23eMHriF2Yeoi", "NY08Fa7grB4I1AOOcrjKN2b9w6sWke5GCA8rpxBM");
    Parse.serverURL = "https://parseapi.back4app.com/";

    let pc = null;
    let stream = null;

    async function init() {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const session = await Parse.Cloud.run("createEphemeralSession", {
          model: "gpt-4o-realtime-preview",
          voice: "verse"
        });

        pc = new RTCPeerConnection({
          iceServers: session.iceServers,
          iceTransportPolicy: "relay"
        });

        stream.getTracks().forEach(track => pc.addTrack(track));
        pc.ontrack = e => document.getElementById('audioOutput').srcObject = e.streams[0];

        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);

        const answer = await Parse.Cloud.run("forwardToOpenAI", {
          sessionId: session.sessionId,
          sdp: offer.sdp
        });

        await pc.setRemoteDescription(answer);
        document.getElementById('status').style.display = 'block';
        log('Verbunden mit OpenAI');
      } catch (error) {
        log(`Fehler: ${error.message}`);
      }
    }

    function log(message) {
      document.getElementById('logs').textContent += `[${new Date().toLocaleTimeString()}] ${message}\n`;
    }

    async function toggle() {
      if (pc?.connectionState === 'connected') {
        pc.close();
        stream.getTracks().forEach(track => track.stop());
        document.getElementById('status').style.display = 'none';
        log('Verbindung getrennt');
      } else {
        await init();
      }
    }
  </script>
</body>
</html>
