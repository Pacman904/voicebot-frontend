<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>WebRTC mit OpenAI</title>
  <style>
    body { 
      font-family: Arial; 
      display: flex; 
      justify-content: center; 
      align-items: center; 
      height: 100vh; 
      background: #f4f4f4; 
    }
    .container { 
      background: white; 
      padding: 20px; 
      border-radius: 8px; 
      box-shadow: 0 2px 8px rgba(0,0,0,0.1); 
      text-align: center;
    }
    button { 
      padding: 12px 24px; 
      background: #007bff; 
      color: white; 
      border: none; 
      border-radius: 4px; 
      cursor: pointer; 
      margin: 10px;
    }
    #onAir { 
      margin-top: 15px; 
      font-size: 20px; 
      color: green; 
      display: none; 
    }
    audio { 
      width: 100%; 
      margin: 15px 0; 
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>OpenAI VoiceBot</h1>
    <button id="startButton">Verbindung starten</button>
    <div id="onAir">Verbunden!</div>
    <audio id="openAIAudio" controls></audio>
    <audio id="userAudio" controls></audio>
  </div>
  <script src="https://unpkg.com/parse/dist/parse.min.js"></script>
  <script>
    Parse.initialize("uNEbQKjymSX8qmK9gorQNRbSuaV23eMHriF2Yeoi", "NY08Fa7grB4I1AOOcrjKN2b9w6sWke5GCA8rpxBM");
    Parse.serverURL = "https://parseapi.back4app.com/";

    let peerConnection = null;
    let userStream = null;
    const startButton = document.getElementById('startButton');
    const onAirElement = document.getElementById('onAir');
    const openAIAudioEl = document.getElementById('openAIAudio');
    const userAudioEl = document.getElementById('userAudio');

    // Initialisiere WebRTC
    async function initializeWebRTC(iceServers, clientSecret, parseSessionId) {
      const configuration = {
        iceServers: iceServers || [
          { urls: "stun:stun.l.google.com:19302" },
          { urls: "turn:your-turn-server.com", username: "turn-user", credential: "turn-pass" } //珊瑚修正：TURN-Server hinzufügen
        ]
      };

      peerConnection = new RTCPeerConnection(configuration);

      // ICE-Kandidaten senden
      peerConnection.onicecandidate = async (event) => {
        if (event.candidate) {
          console.log("ICE-Kandidat:", event.candidate);
          try {
            await sendSignalingData(parseSessionId, {
              type: "candidate",
              candidate: event.candidate.candidate
            });
          } catch (error) {
            console.error("Signaling-Fehler:", error);
          }
        }
      };

      // Verbindungszustand überwachen
      peerConnection.onconnectionstatechange = () => {
        console.log("Verbindungsstatus:", peerConnection.connectionState);
        if (peerConnection.connectionState === "connected") {
          onAirElement.style.display = "block";
          // Starte Audio-Streaming
          userStream.getAudioTracks().forEach(track => peerConnection.addTrack(track));
        }
      };

      // Empfange OpenAI-Audio
      peerConnection.ontrack = (event) => {
        console.log("OpenAI Audio-Track empfangen:", event.track);
        openAIAudioEl.srcObject = event.streams[0];
      };

      // Data-Channel für Echtzeit-Kommunikation
      const dc = peerConnection.createDataChannel("oaiControlEvents");
      dc.onopen = () => {
        console.log("Data-Channel verbunden");
        // Sendet Start-Event zu OpenAI
        dc.send(JSON.stringify({ type: "start" }));
      };
      dc.onmessage = (e) => {
        console.log("OpenAI Event:", JSON.parse(e.data));
        // Handle Text-Antworten hier
      };

      return peerConnection;
    }

    // Starte Verbindung
    async function startConnection() {
      try {
        console.log("Verbindungsaufbau gestartet...");
        onAirElement.style.display = "block";

        // Hole Session-Daten
        const response = await Parse.Cloud.run("createEphemeralSession", {
          model: "gpt-4o-mini-realtime-preview-2024-12-17",
          voice: "verse"
        });

        console.log("Server Response:", response);

        if (!response.sessionId || !response.clientSecret || !response.iceServers) {
          throw new Error("Ungültige Server-Antwort");
        }

        // Hole Mikrofon-Stream
        userStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        userAudioEl.srcObject = userStream;

        // Initialisiere WebRTC
        await initializeWebRTC(
          response.iceServers, 
          response.clientSecret, 
          response.sessionId
        );

        // Signaling-Prozess
        await handleSignaling(response.sessionId, response.clientSecret);
      } catch (error) {
        console.error("Fehler:", error);
        alert(error.message);
      } finally {
        onAirElement.style.display = "none";
      }
    }

    // Signaling-Funktion
    async function handleSignaling(sessionId, clientSecret) {
      if (!peerConnection) throw new Error("WebRTC nicht initialisiert");

      try {
        // Erstelle SDP-Angebot
        const offer = await peerConnection.createOffer({
          offerToReceiveAudio: true,
          offerToReceiveVideo: false
        });
        await peerConnection.setLocalDescription(offer);

        // Sende SDP-Angebot an Backend
        await Parse.Cloud.run("sendSignalingData", {
          sessionId: sessionId,
          data: { type: "offer", sdp: offer.sdp }
        });

        // Sende SDP-Angebot an OpenAI
        const sdpResponse = await fetch(`https://api.openai.com/v1/realtime?model=gpt-4o-mini-realtime-preview-2024-12-17`, {
          method: "POST",
          body: offer.sdp,
          headers: {
            Authorization: `Bearer ${clientSecret}`,
            "Content-Type": "application/sdp"
          }
        });

        if (!sdpResponse.ok) {
          const errorData = await sdpResponse.json();
          throw new Error(`OpenAI-Fehler: ${errorData.error?.message || "Unbekannter Fehler"}`);
        }

        // Setze SDP-Antwort
        const answerSdp = await sdpResponse.text();
        await peerConnection.setRemoteDescription({
          type: "answer",
          sdp: answerSdp
        });

        // Warte auf OpenAI-Audio
        const answerChannel = await new Promise((resolve) => {
          const interval = setInterval(async () => {
            const results = await Parse.Cloud.run("getSignalingData", { sessionId });
            if (results.length > 0) {
              clearInterval(interval);
              resolve(results[0]);
            }
          }, 1000);
        });

        await peerConnection.setRemoteDescription(answerChannel);

      } catch (error) {
        console.error("Signaling-Fehler:", error);
        throw error;
      }
    }

    // Sendet Signaling-Daten
    async function sendSignalingData(sessionId, data) {
      try {
        await Parse.Cloud.run("sendSignalingData", {
          sessionId: sessionId,
          data: data
        });
      } catch (error) {
        console.error("Signaling-Fehler:", error);
        throw error;
      }
    }

    // Event-Listener
    startButton.addEventListener('click', startConnection);

    // Cleanup
    window.addEventListener('beforeunload', () => {
      if (peerConnection) peerConnection.close();
      if (userStream) userStream.getTracks().forEach(track => track.stop());
    });
  </script>
</body>
</html>
