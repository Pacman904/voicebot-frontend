<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voicebot</title>
</head>
<body>
  <div class="phone smartphone">
    <div class="status" id="status">Disconnected</div>
    <button id="callButton" class="button">Start Call</button>
    <div class="output" id="output"></div>
  </div>
  <div class="phone nokia">
    <div class="error" id="error"></div>
  </div>

  <script src="https://unpkg.com/parse/dist/parse.min.js"></script>
  <script>
    Parse.initialize("uNEbQKjymSX8qmK9gorQNRbSuaV23eMHriF2Yeoi", "NY08Fa7grB4I1AOOcrjKN2b9w6sWke5GCA8rpxBM");
    Parse.serverURL = "https://parseapi.back4app.com/";

    let peerConnection;
    let ws;
    let sessionId;
    let openaiSessionId;

    const callButton = document.getElementById("callButton");
    const statusDiv = document.getElementById("status");
    const outputDiv = document.getElementById("output");
    const errorDiv = document.getElementById("error");

    callButton.addEventListener("click", async () => {
      if (callButton.classList.contains("active")) {
        // Verbindung beenden
        if (ws) ws.close();
        if (peerConnection) peerConnection.close();
        callButton.classList.remove("active");
        callButton.textContent = "Start Call";
        statusDiv.textContent = "Disconnected";
        outputDiv.textContent = "";
        return;
      }

      try {
        callButton.classList.add("active");
        callButton.textContent = "End Call";
        statusDiv.textContent = "Connecting...";

        // Session vom Backend abrufen
        const response = await Parse.Cloud.run("createEphemeralSession", {
          model: "gpt-4o-realtime-preview-2024-12-17",
          voice: "verse",
        });
        sessionId = response.sessionId;
        openaiSessionId = response.openaiSessionId;
        const iceServers = response.iceServers;

        // WebRTC-Verbindung initialisieren
        peerConnection = new RTCPeerConnection({ iceServers });
        peerConnection.onicecandidate = (event) => {
          if (event.candidate) {
            console.log("ICE Candidate:", event.candidate);
          }
        };
        peerConnection.onconnectionstatechange = () => {
          console.log("Connection state:", peerConnection.connectionState);
          if (peerConnection.connectionState === "connected") {
            statusDiv.textContent = "Active Call";
          }
        };
        peerConnection.ontrack = (event) => {
          const audioEl = document.createElement("audio");
          audioEl.autoplay = true;
          audioEl.srcObject = event.streams[0];
          document.body.appendChild(audioEl);
        };

        // WebSocket-Verbindung zur OpenAI Realtime API
        ws = new WebSocket(`wss://api.openai.com/v1/realtime/${openaiSessionId}`, {
          headers: { "OpenAI-Beta": "realtime=v1" },
        });

        ws.onopen = () => {
          console.log("WebSocket-Verbindung geÃ¶ffnet");
          ws.send(JSON.stringify({
            type: "session.update",
            session: {
              modalities: ["audio", "text"],
              instructions: "Du bist ein hilfreicher Voicebot.",
            },
          }));
        };

        ws.onmessage = (event) => {
          const data = JSON.parse(event.data);
          if (data.type === "response.text") {
            outputDiv.textContent += `${data.text}\n`;
          } else if (data.type === "response.audio") {
            const audioBlob = new Blob([Buffer.from(data.audio, "base64")], { type: "audio/webm" });
            const audioUrl = URL.createObjectURL(audioBlob);
            new Audio(audioUrl).play();
          }
        };

        ws.onerror = (error) => {
          errorDiv.textContent = "Verbindungsfehler zur OpenAI API";
          console.error("WebSocket-Fehler:", error);
        };

        ws.onclose = () => {
          statusDiv.textContent = "Disconnected";
          callButton.classList.remove("active");
          callButton.textContent = "Start Call";
        };

        // Audio vom Mikrofon aufnehmen und senden
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        peerConnection.addTrack(stream.getAudioTracks()[0], stream);

        const mediaRecorder = new MediaRecorder(stream);
        mediaRecorder.ondataavailable = (event) => {
          if (ws.readyState === WebSocket.OPEN) {
            ws.send(event.data); // Audio an OpenAI senden
          }
        };
        mediaRecorder.start(1000); // Audio alle 1 Sekunde senden

      } catch (error) {
        errorDiv.textContent = `Fehler: ${error.message}`;
        console.error("Fehler beim Verbindungsaufbau:", error);
        callButton.classList.remove("active");
        callButton.textContent = "Start Call";
        statusDiv.textContent = "Disconnected";
      }
    });
  </script>
</body>
</html>
